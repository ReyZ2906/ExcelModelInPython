#!/usr/bin/env python
# -*- coding: utf-8 -*-

import pathlib
import logging
import zipfile
import tempfile
import shutil
from typing import Dict, List, Optional

import pandas as pd
from openpyxl.styles import PatternFill, Border, Side, Font, Alignment
from openpyxl.utils import get_column_letter

# -------------------------------------------------------------------
# Logging
# -------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)-8s %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
log = logging.getLogger(__name__)

# -------------------------------------------------------------------
# Paths
# -------------------------------------------------------------------
PROJECT_ROOT = pathlib.Path(__file__).resolve().parents[2]
DATA_DIR = PROJECT_ROOT / "data"
CSV_DIR = PROJECT_ROOT / "csv"
DEAL_ID_XLSX = PROJECT_ROOT / "data" / "deal_id_list.xlsx"
OUTPUT_XLSX = PROJECT_ROOT / "validation_results.xlsx"

CSV_DIR.mkdir(exist_ok=True)

# -------------------------------------------------------------------
# File-type helpers
# -------------------------------------------------------------------
def _is_zip_file(p: pathlib.Path) -> bool:
    try:
        return p.read_bytes()[:2] == b"PK"
    except Exception:
        return False


def _is_text_file(p: pathlib.Path) -> bool:
    try:
        p.read_bytes()[:1024].decode("utf-8")
        return True
    except UnicodeDecodeError:
        return False
    except Exception:
        return False


def _read_excel_as_text(path: pathlib.Path) -> pd.DataFrame:
    suffix = path.suffix.lower()

    if suffix in (".xlsx", ".xlsm") or _is_zip_file(path):
        df = pd.read_excel(path, dtype=str, engine="openpyxl")
        return df.astype(str)

    if suffix == ".xls":
        df = pd.read_excel(path, dtype=str, engine="xlrd")
        return df.astype(str)

    if _is_text_file(path):
        return pd.read_csv(path, sep="|", dtype=str, engine="python")

    raise ValueError(
        f"Cannot determine format of '{path}'. Supported: xlsx/xlsm/xls/txt(pipe)."
    )


def _convert_to_csv(src_path: pathlib.Path) -> Optional[pathlib.Path]:
    csv_path = CSV_DIR / (src_path.stem + ".csv")

    if _is_text_file(src_path):
        if not csv_path.exists():
            src_path.rename(csv_path)
            log.info(f"Renamed text to CSV: {src_path.name} -> {csv_path.name}")
        return csv_path

    if csv_path.exists():
        return csv_path

    try:
        df = _read_excel_as_text(src_path)
        df.to_csv(csv_path, sep="|", index=False)
        log.info(f"Converted {src_path.name} → {csv_path.name}")
    except Exception as exc:
        log.error(f"Failed to convert {src_path.name}: {exc}")
        return None

    return csv_path

# -------------------------------------------------------------------
# Cleaning helpers (strict XML-safe)
# -------------------------------------------------------------------
def _clean_excel_string(value):
    """Keep only XML 1.0 legal chars so openpyxl never crashes."""
    if not isinstance(value, str):
        return value

    def allowed(ch):
        cp = ord(ch)
        return (
            cp == 0x9
            or cp == 0xA
            or cp == 0xD
            or 0x20 <= cp <= 0xD7FF
            or 0xE000 <= cp <= 0xFFFD
            or 0x10000 <= cp <= 0x10FFFF
        )

    return "".join(ch for ch in value if allowed(ch))


def _sanitize_dataframe_for_excel(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    return df.applymap(_clean_excel_string)

# -------------------------------------------------------------------
# Normalisation
# -------------------------------------------------------------------
def _normalise_column_name(name: str) -> str:
    return name.replace("\u00a0", " ").replace("\u202f", " ").strip()


def _normalise_status_column(df: pd.DataFrame) -> pd.DataFrame:
    """Ensure AUTMATION STATUS column exists (file column, not touched semantically)."""
    candidates = [c for c in df.columns if "automation" in c.lower() and "status" in c.lower()]

    if not candidates:
        df["AUTOMATION STATUS"] = ""
    else:
        if candidates[0] != "AUTOMATION STATUS":
            df.rename(columns={candidates[0]: "AUTOMATION STATUS"}, inplace=True)

    df["AUTOMATION STATUS"] = df["AUTOMATION STATUS"].fillna("").astype(str)
    return df


def _mark_status_read_error(df: pd.DataFrame) -> pd.DataFrame:
    """
    Mark rows that look problematic as 'Read Error' in Status:
      - any cell starting with '='  (formula-like)
    """
    if df.empty:
        return df

    if "Status" not in df.columns:
        df["Status"] = ""

    formula_mask = df.applymap(
        lambda v: isinstance(v, str) and v.startswith("=")
    ).any(axis=1)

    df.loc[formula_mask, "Status"] = "Read Error"
    return df

# -------------------------------------------------------------------
# CSV loading
# -------------------------------------------------------------------
def _load_csv(path: pathlib.Path, source_label: str) -> pd.DataFrame:
    id_col = "CORTEX DEPOSIT DEAL ID"

    try:
        df = pd.read_csv(
            path,
            sep="|",
            dtype=str,
            engine="python",
            on_bad_lines="warn",  # robust against bad lines
        )
        df["Report"] = source_label

        if id_col not in df.columns:
            raise KeyError(f"{id_col} missing in {path.name}")

        df[id_col] = (
            df[id_col]
            .astype(str)
            .str.replace("\u00a0", " ", regex=False)
            .str.replace("\u202f", " ", regex=False)
            .str.strip()
            .str.upper()
        )

        df = _normalise_status_column(df)
        df = _mark_status_read_error(df)

        # Default Status for rows that are not formulas/read errors
        df.loc[df["Status"] == "", "Status"] = "Found"

        return df

    except Exception as exc:
        log.error(f"CSV read failure {path.name}: {exc}")

        return pd.DataFrame(
            [{
                id_col: f"READ_ERROR::{path.name}",
                "AUTOMATION STATUS": "",
                "Status": "Read Error",
                "Report": source_label,
            }]
        )

# -------------------------------------------------------------------
# Styling
# -------------------------------------------------------------------
def _style_worksheet(ws, status_col_idx: Optional[int]):
    # Borders
    thin = Side(border_style="thin", color="000000")
    border = Border(left=thin, right=thin, top=thin, bottom=thin)
    for row in ws.iter_rows():
        for cell in row:
            cell.border = border

    # Header
    header_fill = PatternFill(start_color="1F4E78", end_color="1F4E78", fill_type="solid")
    header_font = Font(bold=True, color="FFFFFF")
    for cell in ws[1]:
        cell.fill = header_fill
        cell.font = header_font
        cell.alignment = Alignment(horizontal="center", vertical="center")

    # Status-based colors
    if status_col_idx:
        col_letter = get_column_letter(status_col_idx)

        green = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
        red = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
        yellow = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
        red_font = Font(color="FF0000")

        for cell in ws[col_letter][1:]:
            v = str(cell.value).strip().lower()

            if v == "found":
                cell.fill = green

            elif v == "not found":
                cell.fill = red

            elif v == "read error":
                cell.fill = yellow
                cell.font = red_font

    # Auto width
    for col in ws.columns:
        length = max(len(str(c.value) if c.value else "") for c in col)
        ws.column_dimensions[col[0].column_letter].width = length + 2


def _get_status_col(ws, header="Status"):
    for i, cell in enumerate(ws[1], start=1):
        if str(cell.value).strip().lower() == header.lower():
            return i
    return None


def _write_sheet(df, writer, sheet, header="Status"):
    df.to_excel(writer, index=False, sheet_name=sheet)
    ws = writer.sheets[sheet]
    idx = _get_status_col(ws, header)
    _style_worksheet(ws, idx)

# -------------------------------------------------------------------
# Report discovery
# -------------------------------------------------------------------
def find_all_reports() -> Dict[str, List[pathlib.Path]]:
    raw = {
        "success": "FTD_SUCC_DEALS_1_*.xls*",
        "failure": "FTD_FAIL_DEALS_1_*.xls*",
    }

    csv_paths = {"success": [], "failure": []}
    found_raw = False

    # 1) Try raw Excel
    for kind, pattern in raw.items():
        matches = list(DATA_DIR.glob(pattern))
        if matches:
            found_raw = True
            for m in matches:
                c = _convert_to_csv(m)
                if c:
                    csv_paths[kind].append(c)

    # 2) If not, try ZIPs
    if not found_raw:
        zip_patterns = {
            "success": "Success_*.zip",
            "failure": "Failure_*.zip",
        }
        for kind, pattern in zip_patterns.items():
            for z in DATA_DIR.glob(pattern):
                with tempfile.TemporaryDirectory() as t:
                    tmp = pathlib.Path(t)
                    with zipfile.ZipFile(z, "r") as zf:
                        zf.extractall(tmp)
                    for f in tmp.rglob("*"):
                        if f.suffix.lower() in (".xls", ".xlsx", ".xlsm", ".txt"):
                            dest = DATA_DIR / f.name
                            shutil.move(str(f), dest)
                            c = _convert_to_csv(dest)
                            if c:
                                csv_paths[kind].append(c)

    # 3) Fallback: direct CSVs
    if not any(csv_paths.values()):
        fallback = {
            "success": "FTD_SUCC_DEALS_1_*.csv",
            "failure": "FTD_FAIL_DEALS_1_*.csv",
        }
        for kind, pattern in fallback.items():
            csv_paths[kind] = list(CSV_DIR.glob(pattern))

    return csv_paths

# -------------------------------------------------------------------
# Deal IDs
# -------------------------------------------------------------------
def _load_deal_ids() -> List[str]:
    df = pd.read_excel(DEAL_ID_XLSX, sheet_name="DealIDs", dtype=str)
    df.columns = [_normalise_column_name(c) for c in df.columns]
    col = "CORTEX DEPOSIT DEAL ID"

    return (
        df[col]
        .dropna()
        .astype(str)
        .str.strip()
        .str.replace("\u00a0", " ", regex=False)
        .str.replace("\u202f", " ", regex=False)
        .str.upper()
        .tolist()
    )

# -------------------------------------------------------------------
# Result frame
# -------------------------------------------------------------------
def _build_result_frame(deal_ids, combined):
    rows = []

    for did in deal_ids:
        match = combined[combined["CORTEX DEPOSIT DEAL ID"] == did]

        if not match.empty:
            row = match.iloc[0].to_dict()
            row.pop("Report", None)

            # Default: Found
            status = "Found"

            # If any row for that deal has Read Error → Read Error overrides
            if "Status" in match.columns:
                if any(match["Status"].str.lower() == "read error"):
                    status = "Read Error"
        else:
            # No matching row in any report → Not Found
            row = {c: "" for c in combined.columns if c != "Report"}
            status = "Not Found"

        rows.append({"Deals-To-Check": did, "Status": status, **row})

    cols = ["Deals-To-Check", "Status"] + [
        c for c in combined.columns if c not in ("Report", "Status")
    ]

    return pd.DataFrame(rows, columns=cols)

# -------------------------------------------------------------------
# MAIN
# -------------------------------------------------------------------
def main():
    csvs = find_all_reports()
    deal_ids = _load_deal_ids()

    success_frames = [_load_csv(p, "Success") for p in csvs["success"]]
    failure_frames = [_load_csv(p, "Failure") for p in csvs["failure"]]

    success_df = pd.concat(success_frames, ignore_index=True) if success_frames else pd.DataFrame()
    failure_df = pd.concat(failure_frames, ignore_index=True) if failure_frames else pd.DataFrame()

    if not success_df.empty and not failure_df.empty:
        combined = pd.concat([success_df, failure_df], ignore_index=True)
    else:
        combined = success_df if not success_df.empty else failure_df

    allmatched = _build_result_frame(deal_ids, combined)

    # sanitize for Excel
    allmatched = _sanitize_dataframe_for_excel(allmatched)

    # ensure AUTMATION STATUS present
    if "AUTOMATION STATUS" not in allmatched.columns:
        allmatched["AUTOMATION STATUS"] = ""

    # bifurcation (only deals with Status=Found)
    success_mask = (
        (allmatched["Status"].str.lower() == "found")
        & (allmatched["AUTOMATION STATUS"].str.upper() == "SUCCESS")
    )

    fail_mask = (
        (allmatched["Status"].str.lower() == "found")
        & (allmatched["AUTOMATION STATUS"].str.upper().isin(["FAILED", "FAILURE"]))
    )

    matched_success = allmatched[success_mask]
    matched_fail = allmatched[fail_mask]

    with pd.ExcelWriter(OUTPUT_XLSX, engine="openpyxl") as writer:
        # AllMatched → color by Status (Found / Not Found / Read Error)
        _write_sheet(allmatched, writer, "AllMatched", "Status")

        # Bifurcated → color by AUTOMATION STATUS
        _write_sheet(matched_success, writer, "AllMatched_Success", "AUTOMATION STATUS")
        _write_sheet(matched_fail, writer, "AllMatched_Fail", "AUTOMATION STATUS")

    print(f"Output Excel generated: {OUTPUT_XLSX}")
    log.info(f"Output Excel generated: {OUTPUT_XLSX}")


if __name__ == "__main__":
    main()
